{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/andrew.cmu.edu/usr8/bmarimut/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Fused window process have not been installed. Please refer to get_started.md for installation.\n",
      "Tutel has not been installed. To use Swin-MoE, please install Tutel; otherwise, just ignore this.\n",
      "To use FusedLAMB or FusedAdam, please install apex.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import argparse\n",
    "from logger import create_logger\n",
    "import os\n",
    "\n",
    "\n",
    "from utils import load_checkpoint, load_pretrained\n",
    "from config import get_config\n",
    "from data import build_loader\n",
    "from models import build_model\n",
    "\n",
    "from main import train_one_epoch, validate, throughput\n",
    "\n",
    "from config import get_only_config\n",
    "import json\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "\n",
    "import datetime\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from timm.utils import accuracy, AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> merge config from configs/swin/swin_tiny_patch4_window7_224_resisc45.yaml\n"
     ]
    }
   ],
   "source": [
    "config_path = 'configs/swin/swin_tiny_patch4_window7_224_resisc45.yaml'\n",
    "config = get_only_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.defrost()\n",
    "config.OUTPUT = \"/afs/ece.cmu.edu/usr/bmarimut/Private/output\"\n",
    "# config.MODEL.PRETRAINED = \"/afs/ece.cmu.edu/usr/ashwinve/Public/ckpt_epoch_29_6.pth\"\n",
    "config.MODEL.PRETRAINED = \"/afs/ece.cmu.edu/usr/ashwinve/Public/golden_resisc45.pth\"\n",
    "config.MODEL.RESUME = \"/afs/ece.cmu.edu/usr/ashwinve/Public/golden_resisc45.pth\"\n",
    "config.DATA.CACHE_MODE = 'no'\n",
    "config.DATA.DATA_PATH = './data/RESISC45/'\n",
    "config.DATA.ZIP_MODE = True\n",
    "config.PRINT_FREQ = 120\n",
    "config.DATA.BATCH_SIZE = 8\n",
    "config.freeze()\n",
    "os.makedirs(config.OUTPUT, exist_ok=True)\n",
    "logger = create_logger(output_dir=config.OUTPUT, name=f\"{config.MODEL.NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/andrew.cmu.edu/usr8/bmarimut/.local/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model = build_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['layers.3.blocks.0.attn.lora_k.weight', 'layers.3.blocks.0.attn.lora_v.weight', 'layers.3.blocks.0.attn.lora_rpb.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(config.MODEL.PRETRAINED, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_pretrained(config, model, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze specific layers for downstream task training\n",
    "# model_named_params = list(model.named_parameters())\n",
    "# num_params = len(model_named_params)\n",
    "# for param_iter in range(num_params):\n",
    "#     param_name, param = model_named_params[param_iter]\n",
    "#     if \"lora\" not in param_name:\n",
    "#         param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-04 20:09:26 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-6-976b1619f3f7> 2)\u001b[0m: INFO number of params: 31913979\n",
      "\u001b[32m[2022-12-04 20:09:26 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-6-976b1619f3f7> 5)\u001b[0m: INFO number of GFLOPs: 4.489983744\n"
     ]
    }
   ],
   "source": [
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(f\"number of params: {n_parameters}\")\n",
    "if hasattr(model, 'flops'):\n",
    "    flops = model.flops()\n",
    "    logger.info(f\"number of GFLOPs: {flops / 1e9}\")\n",
    "\n",
    "model.cuda()\n",
    "model_without_ddp = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_val, data_loader_train, data_loader_val, mixup_fn = build_loader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_SELECTOR = 0\n",
    "LORA_RANK_DICT = {\n",
    "    'layers.0.blocks.0.attn': [9,   12, 13, 49],\n",
    "    'layers.0.blocks.1.attn': [28,  35, 38, 49],\n",
    "    'layers.1.blocks.0.attn': [24,  32, 39, 49],\n",
    "    'layers.1.blocks.1.attn': [19,  22, 23, 49],\n",
    "    'layers.2.blocks.0.attn': [16,  18, 19, 49],\n",
    "    'layers.2.blocks.1.attn': [20,  22, 22, 49],\n",
    "    'layers.2.blocks.2.attn': [22,  26, 30, 49],\n",
    "    'layers.2.blocks.3.attn': [22,  25, 26, 49],\n",
    "    'layers.2.blocks.4.attn': [24,  24, 25, 49],\n",
    "    'layers.2.blocks.5.attn': [23,  24, 24, 49],\n",
    "    'layers.3.blocks.0.attn': [20,  21, 22, 49],\n",
    "    'layers.3.blocks.1.attn': [16,  16, 17, 49]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn_md = get_attn(2,5)\n",
    "# print(get_attn(2,5).input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(list(model.children())[2][0].children())[0][1])\n",
    "# print(get_attn(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# # import models\n",
    "# import sys\n",
    "# importlib.reload(sys.modules['models'])\n",
    "# from models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LORA_WindowAttention2(torch.nn.Module):\n",
    "    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
    "    It supports both of shifted and non-shifted window.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        window_size (tuple[int]): The height and width of the window.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\n",
    "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
    "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, lora_rank, window_size, num_heads, param_name, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size  # Wh, Ww\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        # define a parameter table of relative position bias\n",
    "        self.relative_position_bias_table = torch.nn.Parameter(\n",
    "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
    "\n",
    "        # get pair-wise relative position index for each token inside the window\n",
    "        coords_h = torch.arange(self.window_size[0])\n",
    "        coords_w = torch.arange(self.window_size[1])\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "\n",
    "        self.qkv = torch.nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = torch.nn.Dropout(attn_drop)\n",
    "        self.proj = torch.nn.Linear(dim, dim)\n",
    "        self.proj_drop = torch.nn.Dropout(proj_drop)\n",
    "\n",
    "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        \n",
    "        # Defining LORA parameters\n",
    "        # self.lora_k = torch.nn.Parameter(torch.FloatTensor(self.window_size[0] * self.window_size[1], lora_rank), requires_grad=True)\n",
    "        # self.lora_v = torch.nn.Parameter(torch.FloatTensor(self.window_size[0] * self.window_size[1], lora_rank), requires_grad=True)\n",
    "        # self.lora_rpb = torch.nn.Parameter(torch.FloatTensor(self.window_size[0] * self.window_size[1], lora_rank), requires_grad=True)\n",
    "        \n",
    "        self.lora_k = torch.nn.Linear(head_dim * self.window_size[0] * self.window_size[1], head_dim * lora_rank, bias=False)\n",
    "        self.lora_v = torch.nn.Linear(head_dim * self.window_size[0] * self.window_size[1], head_dim * lora_rank, bias=False)\n",
    "        self.lora_rpb = torch.nn.Linear(self.window_size[0] * self.window_size[1] * self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1] * lora_rank, bias=False)\n",
    "\n",
    "        # self.lora_k.weight.data.fill_(0.01)\n",
    "        # self.lora_v.weight.data.fill_(0.01)\n",
    "        # self.lora_rpb.weight.data.fill_(0.01)\n",
    "\n",
    "        self.lora_rank = lora_rank\n",
    "        # torch.nn.init.ones_(self.lora_k)\n",
    "        # torch.nn.init.ones_(self.lora_v)\n",
    "        # torch.nn.init.ones_(self.lora_rpb)\n",
    "        # torch.nn.init.xavier_normal_(self.lora_k)\n",
    "        # torch.nn.init.xavier_normal_(self.lora_v)\n",
    "        # torch.nn.init.xavier_normal_(self.lora_rpb)\n",
    "\n",
    "        # optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=0.1)\n",
    "        # self.optimizer = torch.optim.AdamW(self.parameters(), lr=learning_rate)\n",
    "        lora_params = [p[1] for p in self.named_parameters() if \"lora\" in p[0]]\n",
    "        # print(lora_params)\n",
    "        self.optimizer = torch.optim.Adam(lora_params, lr=learning_rate)\n",
    "        # self.optimizer = torch.optim.AdamW(filter(lambda p[1]: \"lora\" in p[0], self.named_parameters()), lr=learning_rate)\n",
    "\n",
    "        # self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min', patience=1)\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=1500, gamma=0.1)\n",
    "        # create a loss function\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        # self.criterion = torch.nn.L1Loss()\n",
    "\n",
    "        self.param_name = param_name\n",
    "        self.avg_loss = 0\n",
    "\n",
    "        \n",
    "    \n",
    "    def do_backward(self, target, print_log):\n",
    "        self.optimizer.zero_grad()\n",
    "        self.loss = self.criterion(self.output*100.0, target*100.0)\n",
    "        self.loss.backward()\n",
    "        self.avg_loss += self.loss.item()\n",
    "        self.optimizer.step()\n",
    "\n",
    "\n",
    "    def do_lr_step(self):\n",
    "        self.lr_scheduler.step()\n",
    "\n",
    "    \n",
    "    def load_pretrained_weights(self, super_model):\n",
    "        new_sd = copy.deepcopy(self.state_dict())\n",
    "        # for name in params_names_list:\n",
    "        # print(new_sd)\n",
    "        new_sd['qkv.weight'] = super_model.state_dict()[self.param_name+'.qkv.weight']\n",
    "        new_sd['qkv.bias'] = super_model.state_dict()[self.param_name+'.qkv.bias']\n",
    "        \n",
    "        new_sd['relative_position_bias_table'] = super_model.state_dict()[self.param_name+'.relative_position_bias_table']\n",
    "        \n",
    "        self.load_state_dict(new_sd)\n",
    "\n",
    "        # model_named_params = list(self.named_parameters())\n",
    "        # num_params = len(model_named_params)\n",
    "        # for param_iter in range(num_params):\n",
    "        #     param_name, param = model_named_params[param_iter]\n",
    "        #     if \"lora\" not in param_name:\n",
    "        #         param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input features with shape of (num_windows*B, N, C)\n",
    "            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n",
    "        \"\"\"\n",
    "        B_, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        q = q * self.scale\n",
    "        # attn = (q @ k.transpose(-2, -1))\n",
    "        # k_lora = k.transpose(-2, -1) @ self.lora_k\n",
    "\n",
    "        flattened_k = k.transpose(-2, -1).reshape(B_, self.num_heads, -1)\n",
    "        k_lora = self.lora_k(flattened_k).reshape(B_, self.num_heads, C // self.num_heads, self.lora_rank)\n",
    "\n",
    "        attn = (q @ k_lora)\n",
    "\n",
    "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "        \n",
    "        # attn = attn + relative_position_bias.unsqueeze(0)\n",
    "        \n",
    "        rpb = relative_position_bias.unsqueeze(0)\n",
    "\n",
    "        # rpb_lora = rpb @ self.lora_rpb\n",
    "        flattened_rpb = rpb.reshape(self.num_heads, -1)\n",
    "        \n",
    "        # rpb_lora: num_heads * Window_size * window_size * lora_rank\n",
    "        rpb_lora = self.lora_rpb(flattened_rpb).view(self.num_heads, self.window_size[0] * self.window_size[1], self.lora_rank)\n",
    "\n",
    "        attn = attn + rpb_lora\n",
    "\n",
    "        if mask is not None:\n",
    "            # print(\"lora_k: \", self.lora_k.shape)\n",
    "            # print(\"lora_v: \", self.lora_v.shape)\n",
    "            # print(\"lora_rpb: \", self.lora_rpb.shape)\n",
    "            # print(\"attn: \", attn.shape)\n",
    "            # print(\"mask: \", mask.shape)\n",
    "            nW = mask.shape[0]\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N)\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        # x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        # v_lora = (v.transpose(-2, -1) @ self.lora_v).transpose(-2, -1)\n",
    "\n",
    "        flattened_v_lora = v.transpose(-2, -1).reshape(B_, self.num_heads, -1)\n",
    "        v_lora = self.lora_v(flattened_v_lora).reshape(B_, self.num_heads, C // self.num_heads, self.lora_rank).transpose(-2, -1)\n",
    "\n",
    "        x = (attn @ v_lora).transpose(1, 2).reshape(B_, N, C)\n",
    "        \n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        self.output = x\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, window_size={self.window_size}, num_heads={self.num_heads}'\n",
    "\n",
    "    def flops(self, N):\n",
    "        # calculate flops for 1 window with token length of N\n",
    "        flops = 0\n",
    "        # qkv = self.qkv(x)\n",
    "        flops += N * self.dim * 3 * self.dim\n",
    "        \n",
    "        # attn = (q @ k.transpose(-2, -1))\n",
    "        # flops += self.num_heads * N * (self.dim // self.num_heads) * N\n",
    "        #  x = (attn @ v)\n",
    "        # flops += self.num_heads * N * N * (self.dim // self.num_heads)\n",
    "\n",
    "        # TODO: Figure out FLOPS compute\n",
    "        # # transform : k @ lora_k\n",
    "        # flops += k.shape[0] * k.shape[1] * 2 * k.shape[2] * k.shape[3] * k_lora.shape[3]\n",
    "        # # attn: q @ k_lora\n",
    "        # flops += q.shape[0] * q.shape[1] * 2 * q.shape[2] * q.shape[3] * k_lora.shape[3]\n",
    "        # # transform : v @ v_lora\n",
    "        # flops += v.shape[0] * v.shape[1] * 2 * v.shape[2] * v.shape[3] * v_lora.shape[3]\n",
    "        # # op : attn @ v_lora\n",
    "        # flops += attn.shape[0] * attn.shape[1] * 2 * attn.shape[2] * attn.shape[3] * v_lora.shape[3]\n",
    "\n",
    "        # x = self.proj(x)\n",
    "        flops += N * self.dim * self.dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block(my_model, layer_id, block_id):\n",
    "    # print(list(list(model.children())[2][layer_id].children())[0][block_id])\n",
    "    return list(list(my_model.children())[2][layer_id].children())[0][block_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn(my_model, layer_id, block_id):\n",
    "    block = get_block(my_model, layer_id, block_id)\n",
    "    return list(block.children())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_attn(super_model, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_block(super_model, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_DEPTHS = [2, 2, 6, 2]\n",
    "NUM_LAYERS = len(LAYER_DEPTHS)\n",
    "NUM_HEADS = [ 3, 6, 12, 24 ]\n",
    "H = 224\n",
    "W = 224\n",
    "B = 1\n",
    "L = 224 * 224\n",
    "window_size = 7\n",
    "\n",
    "\n",
    "# i = 0\n",
    "# C = 96 * 2**i\n",
    "# num_heads = NUM_HEADS[i]\n",
    "# dim = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lora_attns = []\n",
    "for layer_id in range(NUM_LAYERS):\n",
    "    layer_attns = []\n",
    "    C = 96 * 2**layer_id\n",
    "    num_heads = NUM_HEADS[layer_id]\n",
    "    dim = C\n",
    "    for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "        if block_id%2 == 0 and layer_id>=2:\n",
    "            param_name = 'layers.' + str(layer_id) + \".blocks.\" + str(block_id) + \".attn\"\n",
    "            lora_attn = LORA_WindowAttention2(dim, LORA_RANK_DICT[param_name][LORA_SELECTOR],\n",
    "            to_2tuple(window_size), num_heads, param_name)\n",
    "            lora_attn.cuda()\n",
    "            lora_attn.load_pretrained_weights(super_model)\n",
    "            layer_attns.append(lora_attn)\n",
    "        else:\n",
    "            layer_attns.append(None)\n",
    "    all_lora_attns.append(layer_attns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = LORA_WindowAttention2(dim, LORA_RANK_DICT[param_name][LORA_SELECTOR],\n",
    "            to_2tuple(window_size), num_heads, param_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LORA_WindowAttention(\n",
       "  dim=768, window_size=(7, 7), num_heads=24\n",
       "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "  (softmax): Softmax(dim=-1)\n",
       "  (criterion): L1Loss()\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.load_state_dict(torch.load(\"layers.3.blocks.0.attn.pth\")['state_dict'])\n",
    "tmp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save LoRA Students to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_id in range(NUM_LAYERS):\n",
    "    for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "        if block_id%2 == 0:\n",
    "            param_name = 'layers.' + str(layer_id) + \".blocks.\" + str(block_id) + \".attn\"\n",
    "            torch.save({\n",
    "                'state_dict': all_lora_attns[layer_id][block_id].state_dict()},\n",
    "                param_name+\".pth\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lora_attns = []\n",
    "for layer_id in range(NUM_LAYERS):\n",
    "    layer_attns = []\n",
    "    C = 96 * 2**layer_id\n",
    "    num_heads = NUM_HEADS[layer_id]\n",
    "    dim = C\n",
    "    for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "        if block_id%2 == 0 and layer_id>=2:\n",
    "            param_name = 'layers.' + str(layer_id) + \".blocks.\" + str(block_id) + \".attn\"\n",
    "            lora_attn = LORA_WindowAttention2(dim, LORA_RANK_DICT[param_name][LORA_SELECTOR],\n",
    "            to_2tuple(window_size), num_heads, param_name)\n",
    "            lora_attn.load_state_dict(torch.load(param_name+\".pth\")['state_dict'])\n",
    "            lora_attn.cuda()\n",
    "            layer_attns.append(lora_attn)\n",
    "        else:\n",
    "            layer_attns.append(None)\n",
    "    all_lora_attns.append(layer_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lora_weights(super_model):\n",
    "    new_sm_sd = copy.deepcopy(super_model.state_dict())\n",
    "    for layer_id in range(NUM_LAYERS):\n",
    "        for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "            if block_id%2 == 0 and layer_id>=2:\n",
    "                param_name = 'layers.' + str(layer_id) + \".blocks.\" + str(block_id) + \".attn\"\n",
    "                # for name in params_names_list:\n",
    "                # print(new_sd)\n",
    "                new_sm_sd[param_name+'.lora_k.weight'] = all_lora_attns[layer_id][block_id].state_dict()['lora_k.weight']\n",
    "                new_sm_sd[param_name+'.lora_v.weight'] = all_lora_attns[layer_id][block_id].state_dict()['lora_v.weight']\n",
    "                new_sm_sd[param_name+'.lora_rpb.weight'] = all_lora_attns[layer_id][block_id].state_dict()['lora_rpb.weight']\n",
    "                \n",
    "                super_model.load_state_dict(new_sm_sd)\n",
    "    return super_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_name+'.lora_k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_model = load_lora_weights(super_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super_model.state_dict()['layers.3.blocks.0.attn.lora_k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_lora_attns[0][0].state_dict()\n",
    "# [p[1] for p in all_lora_attns[0][0].named_parameters() if \"lora\" in p[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "# # create a loss function\n",
    "# criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student teacher training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "def teacher_validate(config, data_loader, model):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    attn_loss_meters = []\n",
    "    for layer_id in range(NUM_LAYERS):\n",
    "        block_loss = []\n",
    "        for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "            if block_id%2 == 0:\n",
    "                atn_loss_meter = AverageMeter()\n",
    "                block_loss.append(atn_loss_meter)\n",
    "            else:\n",
    "                block_loss.append(None)\n",
    "        attn_loss_meters.append(block_loss)\n",
    "\n",
    "    acc1_meter = AverageMeter()\n",
    "    acc5_meter = AverageMeter()\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, (images, target) in enumerate(data_loader):\n",
    "        images = images.cuda(non_blocking=False)\n",
    "        target = target.cuda(non_blocking=False)\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast(enabled=config.AMP_ENABLE):\n",
    "                output = model(images)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        loss = criterion(output, target)\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        \n",
    "        # Train student\n",
    "        # for layer_id in range(NUM_LAYERS):\n",
    "        #     for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "        #         if block_id%2 == 0:\n",
    "        #             lora_md = all_lora_attns[layer_id][block_id]\n",
    "        #             teacher_attn = get_attn(super_model, layer_id, block_id)\n",
    "        #             lora_md.forward(teacher_attn.input)\n",
    "        #             lora_md.do_backward(teacher_attn.output, idx % config.PRINT_FREQ == 0)\n",
    "        #             lora_md.do_lr_step()\n",
    "        #             attn_loss_meters[layer_id][block_id].update(lora_md.loss.item(), 1)\n",
    "                    \n",
    "\n",
    "        # Train student\n",
    "        # for layer_id in range(NUM_LAYERS):\n",
    "        #     for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "        #         if block_id%2 == 0:\n",
    "        #             lora_md = all_lora_attns[layer_id][block_id]\n",
    "        #             teacher_attn = get_attn(super_model, layer_id, block_id)\n",
    "        #             param_name = 'layers.' + str(layer_id) + \".blocks.\" + str(block_id) + \".attn\"\n",
    "\n",
    "        #             # with open(param_name+'.ndarray',mode='ba+') as f:\n",
    "        #             #     teacher_attn.input.cpu().numpy().tofile(f)\n",
    "        #             #     teacher_attn.output.cpu().numpy().tofile(f)\n",
    "        #             lora_md.forward(teacher_attn.input)\n",
    "        #             lora_md.do_backward(teacher_attn.output, idx % config.PRINT_FREQ == 0)\n",
    "        #             lora_md.do_lr_step()\n",
    "\n",
    "\n",
    "\n",
    "        loss_meter.update(loss.item(), target.size(0))\n",
    "        acc1_meter.update(acc1.item(), target.size(0))\n",
    "        acc5_meter.update(acc5.item(), target.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if idx % config.PRINT_FREQ == 0:\n",
    "            memory_used = torch.cuda.max_memory_allocated() / (1024.0 * 1024.0)\n",
    "            logger.info(\n",
    "                f'Test: [{idx}/{len(data_loader)}]\\t'\n",
    "                f'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                f'Loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t'\n",
    "                f'Acc@1 {acc1_meter.val:.3f} ({acc1_meter.avg:.3f})\\t'\n",
    "                f'Acc@5 {acc5_meter.val:.3f} ({acc5_meter.avg:.3f})\\t'\n",
    "                f'Mem {memory_used:.0f}MB')\n",
    "            # for layer_id in range(NUM_LAYERS):\n",
    "            #     for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "            #         if block_id%2 == 0:\n",
    "            #             param_name = 'layers.' + str(layer_id) + \".blocks.\" + str(block_id) + \".attn\"\n",
    "            #             print(param_name, \": Loss : \", attn_loss_meters[layer_id][block_id].val, \" : \", attn_loss_meters[layer_id][block_id].avg, \n",
    "            #                 \" LR : \", all_lora_attns[layer_id][block_id].lr_scheduler.get_last_lr())\n",
    "        \n",
    "    logger.info(f' * Acc@1 {acc1_meter.avg:.3f} Acc@5 {acc5_meter.avg:.3f}')\n",
    "    return acc1_meter.avg, acc5_meter.avg, loss_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Start teacher-student training\")\n",
    "start_time = time.time()\n",
    "# for epoch in range(config.TRAIN.START_EPOCH, config.TRAIN.EPOCHS):\n",
    "for epoch in range(0, 10):\n",
    "    # if not config.TEST.SEQUENTIAL:\n",
    "    # data_loader_train.sampler.set_epoch(epoch)\n",
    "\n",
    "    # train_one_epoch(config, model, criterion, data_loader_train, optimizer, epoch, mixup_fn, lr_scheduler=lr_scheduler,\n",
    "    #                 loss_scaler=None)\n",
    "    print(\" Epoch : \", epoch)\n",
    "    acc1, acc5, loss = teacher_validate(config, data_loader_train, super_model)\n",
    "    for layer_id in range(NUM_LAYERS):\n",
    "        for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "            if block_id%2 == 0:\n",
    "                avg_loss = all_lora_attns[layer_id][block_id].avg_loss / len(data_loader_train)\n",
    "                # all_lora_attns[layer_id][block_id].do_lr_step()\n",
    "                # all_lora_attns[layer_id][block_id].do_lr_step(avg_loss)\n",
    "                all_lora_attns[layer_id][block_id].avg_loss = 0\n",
    "\n",
    "    # acc1, acc5, loss = validate(config, data_loader_val, model)\n",
    "    # logger.info(f\"Accuracy of the network on the {len(dataset_val)} test images: {acc1:.1f}%\")\n",
    "    # max_accuracy = max(max_accuracy, acc1)\n",
    "    # logger.info(f'Max accuracy: {max_accuracy:.2f}%')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "logger.info('Training time {}'.format(total_time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc1, acc5, loss = teacher_validate(config, data_loader_val, super_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-04 20:10:28 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-28-74e31e303f0c> 1)\u001b[0m: INFO Start teacher-student inference\n",
      "\u001b[32m[2022-12-04 20:10:29 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-27-9816c90f8ede> 77)\u001b[0m: INFO Test: [0/788]\tTime 0.328 (0.328)\tLoss 0.0012 (0.0012)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\tMem 371MB\n",
      "\u001b[32m[2022-12-04 20:10:46 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-27-9816c90f8ede> 77)\u001b[0m: INFO Test: [120/788]\tTime 0.124 (0.142)\tLoss 0.0000 (0.2510)\tAcc@1 100.000 (92.769)\tAcc@5 100.000 (99.483)\tMem 423MB\n",
      "\u001b[32m[2022-12-04 20:11:02 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-27-9816c90f8ede> 77)\u001b[0m: INFO Test: [240/788]\tTime 0.145 (0.141)\tLoss 0.2149 (0.3139)\tAcc@1 87.500 (90.975)\tAcc@5 100.000 (99.326)\tMem 424MB\n",
      "\u001b[32m[2022-12-04 20:11:19 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-27-9816c90f8ede> 77)\u001b[0m: INFO Test: [360/788]\tTime 0.147 (0.141)\tLoss 0.0325 (0.3828)\tAcc@1 100.000 (89.370)\tAcc@5 100.000 (99.065)\tMem 424MB\n",
      "\u001b[32m[2022-12-04 20:11:36 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-27-9816c90f8ede> 77)\u001b[0m: INFO Test: [480/788]\tTime 0.137 (0.141)\tLoss 1.2087 (0.4198)\tAcc@1 62.500 (88.358)\tAcc@5 100.000 (98.909)\tMem 424MB\n",
      "\u001b[32m[2022-12-04 20:11:53 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-27-9816c90f8ede> 77)\u001b[0m: INFO Test: [600/788]\tTime 0.151 (0.141)\tLoss 0.3516 (0.4564)\tAcc@1 75.000 (87.334)\tAcc@5 100.000 (98.752)\tMem 424MB\n",
      "\u001b[32m[2022-12-04 20:12:10 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-27-9816c90f8ede> 77)\u001b[0m: INFO Test: [720/788]\tTime 0.138 (0.141)\tLoss 0.0286 (0.4198)\tAcc@1 100.000 (88.384)\tAcc@5 100.000 (98.873)\tMem 424MB\n",
      "\u001b[32m[2022-12-04 20:12:19 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-27-9816c90f8ede> 90)\u001b[0m: INFO  * Acc@1 88.857 Acc@5 98.952\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Start teacher-student inference\")\n",
    "start_time = time.time()\n",
    "acc1, acc5, loss = teacher_validate(config, data_loader_val, super_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): BasicLayer(\n",
       "      dim=96, input_resolution=(56, 56), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=96, window_size=(7, 7), num_heads=3\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=96, window_size=(7, 7), num_heads=3\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.018)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(56, 56), dim=96\n",
       "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicLayer(\n",
       "      dim=192, input_resolution=(28, 28), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=192, window_size=(7, 7), num_heads=6\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.036)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=3, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=192, window_size=(7, 7), num_heads=6\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.055)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(28, 28), dim=192\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicLayer(\n",
       "      dim=384, input_resolution=(14, 14), depth=6\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=384, window_size=(7, 7), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.073)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=384, window_size=(7, 7), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=384, window_size=(7, 7), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.109)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=384, window_size=(7, 7), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.127)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=384, window_size=(7, 7), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.145)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=384, window_size=(7, 7), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.164)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(14, 14), dim=384\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): BasicLayer(\n",
       "      dim=768, input_resolution=(7, 7), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): LORA_WindowAttention(\n",
       "            dim=768, window_size=(7, 7), num_heads=24\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (lora_k): Linear(in_features=1568, out_features=640, bias=False)\n",
       "            (lora_v): Linear(in_features=1568, out_features=640, bias=False)\n",
       "            (lora_rpb): Linear(in_features=2401, out_features=980, bias=False)\n",
       "            (criterion): MSELoss()\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.182)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=768, window_size=(7, 7), num_heads=24\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.200)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (head): Linear(in_features=768, out_features=45, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
