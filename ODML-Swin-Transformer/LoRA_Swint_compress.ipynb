{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/andrew.cmu.edu/usr8/bmarimut/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Fused window process have not been installed. Please refer to get_started.md for installation.\n",
      "Tutel has not been installed. To use Swin-MoE, please install Tutel; otherwise, just ignore this.\n",
      "To use FusedLAMB or FusedAdam, please install apex.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import argparse\n",
    "from logger import create_logger\n",
    "import os\n",
    "\n",
    "\n",
    "from utils import load_checkpoint, load_pretrained\n",
    "from config import get_config\n",
    "from data import build_loader\n",
    "from models import build_model\n",
    "\n",
    "from main import train_one_epoch, validate, throughput\n",
    "\n",
    "from config import get_only_config\n",
    "import json\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "\n",
    "import datetime\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from timm.utils import accuracy, AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> merge config from configs/swin/swin_tiny_patch4_window7_224_resisc45.yaml\n"
     ]
    }
   ],
   "source": [
    "config_path = 'configs/swin/swin_tiny_patch4_window7_224_resisc45.yaml'\n",
    "config = get_only_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.defrost()\n",
    "config.OUTPUT = \"/afs/ece.cmu.edu/usr/bmarimut/Private/output\"\n",
    "# config.MODEL.PRETRAINED = \"/afs/ece.cmu.edu/usr/ashwinve/Public/ckpt_epoch_29_6.pth\"\n",
    "config.MODEL.PRETRAINED = \"/afs/ece.cmu.edu/usr/ashwinve/Public/golden_resisc45.pth\"\n",
    "config.MODEL.RESUME = \"/afs/ece.cmu.edu/usr/ashwinve/Public/golden_resisc45.pth\"\n",
    "config.DATA.CACHE_MODE = 'no'\n",
    "config.DATA.DATA_PATH = './data/RESISC45/'\n",
    "config.DATA.ZIP_MODE = True\n",
    "config.PRINT_FREQ = 120\n",
    "config.DATA.BATCH_SIZE = 8\n",
    "config.freeze()\n",
    "os.makedirs(config.OUTPUT, exist_ok=True)\n",
    "logger = create_logger(output_dir=config.OUTPUT, name=f\"{config.MODEL.NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/andrew.cmu.edu/usr8/bmarimut/.local/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model = build_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.q_wUSprime', 'layers.0.blocks.0.attn.q_wVprime', 'layers.0.blocks.0.attn.q_b', 'layers.0.blocks.0.attn.k_wUSprime', 'layers.0.blocks.0.attn.k_wVprime', 'layers.0.blocks.0.attn.k_b', 'layers.0.blocks.0.attn.v_wUSprime', 'layers.0.blocks.0.attn.v_wVprime', 'layers.0.blocks.0.attn.v_b', 'layers.0.blocks.1.attn.q_wUSprime', 'layers.0.blocks.1.attn.q_wVprime', 'layers.0.blocks.1.attn.q_b', 'layers.0.blocks.1.attn.k_wUSprime', 'layers.0.blocks.1.attn.k_wVprime', 'layers.0.blocks.1.attn.k_b', 'layers.0.blocks.1.attn.v_wUSprime', 'layers.0.blocks.1.attn.v_wVprime', 'layers.0.blocks.1.attn.v_b', 'layers.1.blocks.0.attn.q_wUSprime', 'layers.1.blocks.0.attn.q_wVprime', 'layers.1.blocks.0.attn.q_b', 'layers.1.blocks.0.attn.k_wUSprime', 'layers.1.blocks.0.attn.k_wVprime', 'layers.1.blocks.0.attn.k_b', 'layers.1.blocks.0.attn.v_wUSprime', 'layers.1.blocks.0.attn.v_wVprime', 'layers.1.blocks.0.attn.v_b', 'layers.1.blocks.1.attn.q_wUSprime', 'layers.1.blocks.1.attn.q_wVprime', 'layers.1.blocks.1.attn.q_b', 'layers.1.blocks.1.attn.k_wUSprime', 'layers.1.blocks.1.attn.k_wVprime', 'layers.1.blocks.1.attn.k_b', 'layers.1.blocks.1.attn.v_wUSprime', 'layers.1.blocks.1.attn.v_wVprime', 'layers.1.blocks.1.attn.v_b', 'layers.2.blocks.0.attn.q_wUSprime', 'layers.2.blocks.0.attn.q_wVprime', 'layers.2.blocks.0.attn.q_b', 'layers.2.blocks.0.attn.k_wUSprime', 'layers.2.blocks.0.attn.k_wVprime', 'layers.2.blocks.0.attn.k_b', 'layers.2.blocks.0.attn.v_wUSprime', 'layers.2.blocks.0.attn.v_wVprime', 'layers.2.blocks.0.attn.v_b', 'layers.2.blocks.1.attn.q_wUSprime', 'layers.2.blocks.1.attn.q_wVprime', 'layers.2.blocks.1.attn.q_b', 'layers.2.blocks.1.attn.k_wUSprime', 'layers.2.blocks.1.attn.k_wVprime', 'layers.2.blocks.1.attn.k_b', 'layers.2.blocks.1.attn.v_wUSprime', 'layers.2.blocks.1.attn.v_wVprime', 'layers.2.blocks.1.attn.v_b', 'layers.2.blocks.2.attn.q_wUSprime', 'layers.2.blocks.2.attn.q_wVprime', 'layers.2.blocks.2.attn.q_b', 'layers.2.blocks.2.attn.k_wUSprime', 'layers.2.blocks.2.attn.k_wVprime', 'layers.2.blocks.2.attn.k_b', 'layers.2.blocks.2.attn.v_wUSprime', 'layers.2.blocks.2.attn.v_wVprime', 'layers.2.blocks.2.attn.v_b', 'layers.2.blocks.3.attn.q_wUSprime', 'layers.2.blocks.3.attn.q_wVprime', 'layers.2.blocks.3.attn.q_b', 'layers.2.blocks.3.attn.k_wUSprime', 'layers.2.blocks.3.attn.k_wVprime', 'layers.2.blocks.3.attn.k_b', 'layers.2.blocks.3.attn.v_wUSprime', 'layers.2.blocks.3.attn.v_wVprime', 'layers.2.blocks.3.attn.v_b', 'layers.2.blocks.4.attn.q_wUSprime', 'layers.2.blocks.4.attn.q_wVprime', 'layers.2.blocks.4.attn.q_b', 'layers.2.blocks.4.attn.k_wUSprime', 'layers.2.blocks.4.attn.k_wVprime', 'layers.2.blocks.4.attn.k_b', 'layers.2.blocks.4.attn.v_wUSprime', 'layers.2.blocks.4.attn.v_wVprime', 'layers.2.blocks.4.attn.v_b', 'layers.2.blocks.5.attn.q_wUSprime', 'layers.2.blocks.5.attn.q_wVprime', 'layers.2.blocks.5.attn.q_b', 'layers.2.blocks.5.attn.k_wUSprime', 'layers.2.blocks.5.attn.k_wVprime', 'layers.2.blocks.5.attn.k_b', 'layers.2.blocks.5.attn.v_wUSprime', 'layers.2.blocks.5.attn.v_wVprime', 'layers.2.blocks.5.attn.v_b', 'layers.3.blocks.0.attn.q_wUSprime', 'layers.3.blocks.0.attn.q_wVprime', 'layers.3.blocks.0.attn.q_b', 'layers.3.blocks.0.attn.k_wUSprime', 'layers.3.blocks.0.attn.k_wVprime', 'layers.3.blocks.0.attn.k_b', 'layers.3.blocks.0.attn.v_wUSprime', 'layers.3.blocks.0.attn.v_wVprime', 'layers.3.blocks.0.attn.v_b', 'layers.3.blocks.1.attn.q_wUSprime', 'layers.3.blocks.1.attn.q_wVprime', 'layers.3.blocks.1.attn.q_b', 'layers.3.blocks.1.attn.k_wUSprime', 'layers.3.blocks.1.attn.k_wVprime', 'layers.3.blocks.1.attn.k_b', 'layers.3.blocks.1.attn.v_wUSprime', 'layers.3.blocks.1.attn.v_wVprime', 'layers.3.blocks.1.attn.v_b'], unexpected_keys=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(config.MODEL.PRETRAINED, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_qkv_low_rank_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_pretrained(config, model, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze specific layers for downstream task training\n",
    "lora_w_name_pattern = ['q_b', 'k_b', 'v_b', 'prime']\n",
    "\n",
    "n_parameters_orig = 0\n",
    "n_parameters_lora = 0\n",
    "model_named_params = list(model.named_parameters())\n",
    "num_params = len(model_named_params)\n",
    "for param_iter in range(num_params):\n",
    "    param_name, param = model_named_params[param_iter]\n",
    "    # if \"lora\" not in param_name:\n",
    "    if any(substring in param_name for substring in lora_w_name_pattern):\n",
    "        n_parameters_lora += param.numel()\n",
    "    elif \"qkv.weight\" in param_name or \"qkv.bias\" in param_name:\n",
    "        n_parameters_orig += param.numel()\n",
    "    else:\n",
    "        n_parameters_orig += param.numel()\n",
    "        n_parameters_lora += param.numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-06 02:38:21 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-9-fec03b210896> 2)\u001b[0m: INFO number of params: 27553959\n",
      "\u001b[32m[2022-12-06 02:38:21 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-9-fec03b210896> 3)\u001b[0m: INFO number of LoRA params: 26139303\n",
      "\u001b[32m[2022-12-06 02:38:21 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-9-fec03b210896> 8)\u001b[0m: INFO number of GFLOPs: 4.49367168\n",
      "\u001b[32m[2022-12-06 02:38:21 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-9-fec03b210896> 10)\u001b[0m: INFO Lora number of GFLOPs: 3.724774656\n"
     ]
    }
   ],
   "source": [
    "# n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(f\"number of params: {n_parameters_orig}\")\n",
    "logger.info(f\"number of LoRA params: {n_parameters_lora}\")\n",
    "flops = 0\n",
    "flops_lora = 0\n",
    "if hasattr(model, 'flops'):\n",
    "    flops = model.flops()\n",
    "    logger.info(f\"number of GFLOPs: {flops / 1e9}\")\n",
    "    flops_lora = model.flops_lora()\n",
    "    logger.info(f\"Lora number of GFLOPs: {flops_lora / 1e9}\")\n",
    "\n",
    "model.cuda()\n",
    "model_without_ddp = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lora rank 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param savings =  14.30281579500064  % \n",
      "FLOPs savings =  20.12546283755203  % \n"
     ]
    }
   ],
   "source": [
    "print(\"Param savings = \", (n_parameters_orig - n_parameters_lora)/n_parameters_orig*100.0, \" % \")\n",
    "print(\"FLOPs savings = \", (flops - flops_lora)/flops*100.0, \" % \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lora 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param savings =  5.134129727056645  % \n",
      "FLOPs savings =  17.11066314484284  % \n"
     ]
    }
   ],
   "source": [
    "print(\"Param savings = \", (n_parameters_orig - n_parameters_lora)/n_parameters_orig*100.0, \" % \")\n",
    "print(\"FLOPs savings = \", (flops - flops_lora)/flops*100.0, \" % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_val, data_loader_train, data_loader_val, mixup_fn = build_loader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_SELECTOR = 0\n",
    "LORA_RANK_DICT = {\n",
    "    'layers.0.blocks.0.attn': [9,   12, 13, 49],\n",
    "    'layers.0.blocks.1.attn': [28,  35, 38, 49],\n",
    "    'layers.1.blocks.0.attn': [24,  32, 39, 49],\n",
    "    'layers.1.blocks.1.attn': [19,  22, 23, 49],\n",
    "    'layers.2.blocks.0.attn': [16,  18, 19, 49],\n",
    "    'layers.2.blocks.1.attn': [20,  22, 22, 49],\n",
    "    'layers.2.blocks.2.attn': [22,  26, 30, 49],\n",
    "    'layers.2.blocks.3.attn': [22,  25, 26, 49],\n",
    "    'layers.2.blocks.4.attn': [24,  24, 25, 49],\n",
    "    'layers.2.blocks.5.attn': [23,  24, 24, 49],\n",
    "    'layers.3.blocks.0.attn': [20,  21, 22, 49],\n",
    "    'layers.3.blocks.1.attn': [16,  16, 17, 49]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_SELECTOR = 2\n",
    "LORA_RANK_DICT = {\n",
    "    'layers.0.blocks.0.attn': [300, 325, 350, 384],\n",
    "    'layers.0.blocks.1.attn': [300, 325, 350, 384],\n",
    "    'layers.1.blocks.0.attn': [300, 325, 350, 384],\n",
    "    'layers.1.blocks.1.attn': [300, 325, 350, 384],\n",
    "    'layers.2.blocks.0.attn': [300, 325, 350, 384],\n",
    "    'layers.2.blocks.1.attn': [300, 325, 350, 384],\n",
    "    'layers.2.blocks.2.attn': [300, 325, 350, 384],\n",
    "    'layers.2.blocks.3.attn': [300, 325, 350, 384],\n",
    "    'layers.2.blocks.4.attn': [300, 325, 350, 384],\n",
    "    'layers.2.blocks.5.attn': [300, 325, 350, 384],\n",
    "    'layers.3.blocks.0.attn': [300, 325, 350, 384],\n",
    "    'layers.3.blocks.1.attn': [300, 325, 350, 384]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn_md = get_attn(2,5)\n",
    "# print(get_attn(2,5).input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(list(model.children())[2][0].children())[0][1])\n",
    "# print(get_attn(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# # import models\n",
    "# import sys\n",
    "# importlib.reload(sys.modules['models'])\n",
    "# from models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block(my_model, layer_id, block_id):\n",
    "    # print(list(list(model.children())[2][layer_id].children())[0][block_id])\n",
    "    return list(list(my_model.children())[2][layer_id].children())[0][block_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn(my_model, layer_id, block_id):\n",
    "    block = get_block(my_model, layer_id, block_id)\n",
    "    return list(block.children())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_attn(super_model, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_block(super_model, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_DEPTHS = [2, 2, 6, 2]\n",
    "NUM_LAYERS = len(LAYER_DEPTHS)\n",
    "NUM_HEADS = [ 3, 6, 12, 24 ]\n",
    "H = 224\n",
    "W = 224\n",
    "B = 1\n",
    "L = 224 * 224\n",
    "window_size = 7\n",
    "\n",
    "\n",
    "# i = 0\n",
    "# C = 96 * 2**i\n",
    "# num_heads = NUM_HEADS[i]\n",
    "# dim = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/andrew.cmu.edu/usr8/bmarimut/.local/lib/python3.6/site-packages/ipykernel_launcher.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/afs/andrew.cmu.edu/usr8/bmarimut/.local/lib/python3.6/site-packages/ipykernel_launcher.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "all_lora_attns = []\n",
    "for layer_id in range(NUM_LAYERS):\n",
    "    layer_attns = []\n",
    "    C = 96 * 2**layer_id\n",
    "    num_heads = NUM_HEADS[layer_id]\n",
    "    dim = C\n",
    "    for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "        if layer_id>=3:\n",
    "            param_name = 'layers.' + str(layer_id) + \".blocks.\" + str(block_id) + \".attn\"\n",
    "            lora_attn = LORA_WindowAttention3(dim, LORA_RANK_DICT[param_name][LORA_SELECTOR],\n",
    "            to_2tuple(window_size), num_heads, param_name)\n",
    "            lora_attn.load_pretrained_weights(super_model)\n",
    "            lora_attn.init_low_rank_approx_weights()\n",
    "            lora_attn.cuda()\n",
    "            layer_attns.append(lora_attn)\n",
    "        else:\n",
    "            layer_attns.append(None)\n",
    "    all_lora_attns.append(layer_attns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = LORA_WindowAttention2(dim, LORA_RANK_DICT[param_name][LORA_SELECTOR],\n",
    "            to_2tuple(window_size), num_heads, param_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LORA_WindowAttention(\n",
       "  dim=768, window_size=(7, 7), num_heads=24\n",
       "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "  (softmax): Softmax(dim=-1)\n",
       "  (criterion): L1Loss()\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.load_state_dict(torch.load(\"layers.3.blocks.0.attn.pth\")['state_dict'])\n",
    "tmp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save LoRA Students to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_id in range(NUM_LAYERS):\n",
    "    for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "        if block_id%2 == 0:\n",
    "            param_name = 'layers.' + str(layer_id) + \".blocks.\" + str(block_id) + \".attn\"\n",
    "            torch.save({\n",
    "                'state_dict': all_lora_attns[layer_id][block_id].state_dict()},\n",
    "                param_name+\".pth\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lora_attns = []\n",
    "for layer_id in range(NUM_LAYERS):\n",
    "    layer_attns = []\n",
    "    C = 96 * 2**layer_id\n",
    "    num_heads = NUM_HEADS[layer_id]\n",
    "    dim = C\n",
    "    for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "        if block_id%2 == 0 and layer_id>=2:\n",
    "            param_name = 'layers.' + str(layer_id) + \".blocks.\" + str(block_id) + \".attn\"\n",
    "            lora_attn = LORA_WindowAttention2(dim, LORA_RANK_DICT[param_name][LORA_SELECTOR],\n",
    "            to_2tuple(window_size), num_heads, param_name)\n",
    "            lora_attn.load_state_dict(torch.load(param_name+\".pth\")['state_dict'])\n",
    "            lora_attn.cuda()\n",
    "            layer_attns.append(lora_attn)\n",
    "        else:\n",
    "            layer_attns.append(None)\n",
    "    all_lora_attns.append(layer_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lora_weights(super_model):\n",
    "    new_sm_sd = copy.deepcopy(super_model.state_dict())\n",
    "    for layer_id in range(NUM_LAYERS):\n",
    "        for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "            if block_id%2 == 0 and layer_id>=2:\n",
    "                param_name = 'layers.' + str(layer_id) + \".blocks.\" + str(block_id) + \".attn\"\n",
    "                # for name in params_names_list:\n",
    "                # print(new_sd)\n",
    "                new_sm_sd[param_name+'.lora_k.weight'] = all_lora_attns[layer_id][block_id].state_dict()['lora_k.weight']\n",
    "                new_sm_sd[param_name+'.lora_v.weight'] = all_lora_attns[layer_id][block_id].state_dict()['lora_v.weight']\n",
    "                new_sm_sd[param_name+'.lora_rpb.weight'] = all_lora_attns[layer_id][block_id].state_dict()['lora_rpb.weight']\n",
    "                \n",
    "                super_model.load_state_dict(new_sm_sd)\n",
    "    return super_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_name+'.lora_k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_model = load_lora_weights(super_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super_model.state_dict()['layers.3.blocks.0.attn.lora_k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_lora_attns[0][0].state_dict()\n",
    "# [p[1] for p in all_lora_attns[0][0].named_parameters() if \"lora\" in p[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "# # create a loss function\n",
    "# criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student teacher training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "def teacher_validate(config, data_loader, model):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    # attn_loss_meters = []\n",
    "    # for layer_id in range(NUM_LAYERS):\n",
    "    #     block_loss = []\n",
    "    #     for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "    #         if block_id%2 == 0:\n",
    "    #             atn_loss_meter = AverageMeter()\n",
    "    #             block_loss.append(atn_loss_meter)\n",
    "    #         else:\n",
    "    #             block_loss.append(None)\n",
    "    #     attn_loss_meters.append(block_loss)\n",
    "\n",
    "    acc1_meter = AverageMeter()\n",
    "    acc5_meter = AverageMeter()\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, (images, target) in enumerate(data_loader):\n",
    "        images = images.cuda(non_blocking=False)\n",
    "        target = target.cuda(non_blocking=False)\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast(enabled=config.AMP_ENABLE):\n",
    "                output = model(images)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        loss = criterion(output, target)\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        \n",
    "        # Train student\n",
    "        # for layer_id in range(NUM_LAYERS):\n",
    "        #     for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "        #         if block_id%2 == 0:\n",
    "        #             lora_md = all_lora_attns[layer_id][block_id]\n",
    "        #             teacher_attn = get_attn(super_model, layer_id, block_id)\n",
    "        #             lora_md.forward(teacher_attn.input)\n",
    "        #             lora_md.do_backward(teacher_attn.output, idx % config.PRINT_FREQ == 0)\n",
    "        #             lora_md.do_lr_step()\n",
    "        #             attn_loss_meters[layer_id][block_id].update(lora_md.loss.item(), 1)\n",
    "                    \n",
    "\n",
    "        # Train student\n",
    "        # for layer_id in range(NUM_LAYERS):\n",
    "        #     for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "        #         if block_id%2 == 0:\n",
    "        #             lora_md = all_lora_attns[layer_id][block_id]\n",
    "        #             teacher_attn = get_attn(super_model, layer_id, block_id)\n",
    "        #             param_name = 'layers.' + str(layer_id) + \".blocks.\" + str(block_id) + \".attn\"\n",
    "\n",
    "        #             # with open(param_name+'.ndarray',mode='ba+') as f:\n",
    "        #             #     teacher_attn.input.cpu().numpy().tofile(f)\n",
    "        #             #     teacher_attn.output.cpu().numpy().tofile(f)\n",
    "        #             lora_md.forward(teacher_attn.input)\n",
    "        #             lora_md.do_backward(teacher_attn.output, idx % config.PRINT_FREQ == 0)\n",
    "        #             lora_md.do_lr_step()\n",
    "\n",
    "\n",
    "\n",
    "        loss_meter.update(loss.item(), target.size(0))\n",
    "        acc1_meter.update(acc1.item(), target.size(0))\n",
    "        acc5_meter.update(acc5.item(), target.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if idx % config.PRINT_FREQ == 0:\n",
    "            memory_used = torch.cuda.max_memory_allocated() / (1024.0 * 1024.0)\n",
    "            logger.info(\n",
    "                f'Test: [{idx}/{len(data_loader)}]\\t'\n",
    "                f'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                f'Loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t'\n",
    "                f'Acc@1 {acc1_meter.val:.3f} ({acc1_meter.avg:.3f})\\t'\n",
    "                f'Acc@5 {acc5_meter.val:.3f} ({acc5_meter.avg:.3f})\\t'\n",
    "                f'Mem {memory_used:.0f}MB')\n",
    "            # for layer_id in range(NUM_LAYERS):\n",
    "            #     for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "            #         if block_id%2 == 0:\n",
    "            #             param_name = 'layers.' + str(layer_id) + \".blocks.\" + str(block_id) + \".attn\"\n",
    "            #             print(param_name, \": Loss : \", attn_loss_meters[layer_id][block_id].val, \" : \", attn_loss_meters[layer_id][block_id].avg, \n",
    "            #                 \" LR : \", all_lora_attns[layer_id][block_id].lr_scheduler.get_last_lr())\n",
    "        \n",
    "    logger.info(f' * Acc@1 {acc1_meter.avg:.3f} Acc@5 {acc5_meter.avg:.3f}')\n",
    "    return acc1_meter.avg, acc5_meter.avg, loss_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Start teacher-student training\")\n",
    "start_time = time.time()\n",
    "# for epoch in range(config.TRAIN.START_EPOCH, config.TRAIN.EPOCHS):\n",
    "for epoch in range(0, 10):\n",
    "    # if not config.TEST.SEQUENTIAL:\n",
    "    # data_loader_train.sampler.set_epoch(epoch)\n",
    "\n",
    "    # train_one_epoch(config, model, criterion, data_loader_train, optimizer, epoch, mixup_fn, lr_scheduler=lr_scheduler,\n",
    "    #                 loss_scaler=None)\n",
    "    print(\" Epoch : \", epoch)\n",
    "    acc1, acc5, loss = teacher_validate(config, data_loader_train, super_model)\n",
    "    for layer_id in range(NUM_LAYERS):\n",
    "        for block_id in range(LAYER_DEPTHS[layer_id]):\n",
    "            if block_id%2 == 0:\n",
    "                avg_loss = all_lora_attns[layer_id][block_id].avg_loss / len(data_loader_train)\n",
    "                # all_lora_attns[layer_id][block_id].do_lr_step()\n",
    "                # all_lora_attns[layer_id][block_id].do_lr_step(avg_loss)\n",
    "                all_lora_attns[layer_id][block_id].avg_loss = 0\n",
    "\n",
    "    # acc1, acc5, loss = validate(config, data_loader_val, model)\n",
    "    # logger.info(f\"Accuracy of the network on the {len(dataset_val)} test images: {acc1:.1f}%\")\n",
    "    # max_accuracy = max(max_accuracy, acc1)\n",
    "    # logger.info(f'Max accuracy: {max_accuracy:.2f}%')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "logger.info('Training time {}'.format(total_time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc1, acc5, loss = teacher_validate(config, data_loader_val, super_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Layer 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only layer 3 Low rank: 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-06 01:34:26 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-16-74e31e303f0c> 1)\u001b[0m: INFO Start teacher-student inference\n",
      "\u001b[32m[2022-12-06 01:34:26 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-15-d2eb1b709886> 77)\u001b[0m: INFO Test: [0/788]\tTime 0.273 (0.273)\tLoss 0.0000 (0.0000)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\tMem 281MB\n",
      "\u001b[32m[2022-12-06 01:34:31 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-15-d2eb1b709886> 77)\u001b[0m: INFO Test: [120/788]\tTime 0.045 (0.047)\tLoss 0.0000 (0.2428)\tAcc@1 100.000 (93.595)\tAcc@5 100.000 (99.690)\tMem 332MB\n",
      "\u001b[32m[2022-12-06 01:34:37 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-15-d2eb1b709886> 77)\u001b[0m: INFO Test: [240/788]\tTime 0.046 (0.046)\tLoss 0.3912 (0.3083)\tAcc@1 87.500 (92.168)\tAcc@5 100.000 (99.637)\tMem 333MB\n",
      "\u001b[32m[2022-12-06 01:34:42 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-15-d2eb1b709886> 77)\u001b[0m: INFO Test: [360/788]\tTime 0.045 (0.046)\tLoss 0.0099 (0.3497)\tAcc@1 100.000 (91.482)\tAcc@5 100.000 (99.446)\tMem 333MB\n",
      "\u001b[32m[2022-12-06 01:34:48 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-15-d2eb1b709886> 77)\u001b[0m: INFO Test: [480/788]\tTime 0.047 (0.046)\tLoss 0.8984 (0.3861)\tAcc@1 87.500 (90.774)\tAcc@5 100.000 (99.220)\tMem 335MB\n",
      "\u001b[32m[2022-12-06 01:34:53 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-15-d2eb1b709886> 77)\u001b[0m: INFO Test: [600/788]\tTime 0.045 (0.046)\tLoss 0.5625 (0.4228)\tAcc@1 75.000 (89.829)\tAcc@5 100.000 (99.106)\tMem 335MB\n",
      "\u001b[32m[2022-12-06 01:34:59 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-15-d2eb1b709886> 77)\u001b[0m: INFO Test: [720/788]\tTime 0.047 (0.046)\tLoss 0.0275 (0.3890)\tAcc@1 100.000 (90.759)\tAcc@5 100.000 (99.202)\tMem 335MB\n",
      "\u001b[32m[2022-12-06 01:35:02 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-15-d2eb1b709886> 90)\u001b[0m: INFO  * Acc@1 91.095 Acc@5 99.238\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Start teacher-student inference\")\n",
    "start_time = time.time()\n",
    "acc1, acc5, loss = teacher_validate(config, data_loader_val, super_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low rank: 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-06 01:30:23 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-14-74e31e303f0c> 1)\u001b[0m: INFO Start teacher-student inference\n",
      "\u001b[32m[2022-12-06 01:30:24 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [0/788]\tTime 0.263 (0.263)\tLoss 0.0000 (0.0000)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\tMem 284MB\n",
      "\u001b[32m[2022-12-06 01:30:29 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [120/788]\tTime 0.045 (0.046)\tLoss 0.0000 (0.2515)\tAcc@1 100.000 (93.492)\tAcc@5 100.000 (99.690)\tMem 336MB\n",
      "\u001b[32m[2022-12-06 01:30:34 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [240/788]\tTime 0.046 (0.045)\tLoss 0.4213 (0.3145)\tAcc@1 87.500 (92.272)\tAcc@5 100.000 (99.637)\tMem 336MB\n",
      "\u001b[32m[2022-12-06 01:30:40 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [360/788]\tTime 0.046 (0.045)\tLoss 0.0076 (0.3547)\tAcc@1 100.000 (91.551)\tAcc@5 100.000 (99.446)\tMem 336MB\n",
      "\u001b[32m[2022-12-06 01:30:45 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [480/788]\tTime 0.046 (0.045)\tLoss 0.8306 (0.3902)\tAcc@1 87.500 (90.826)\tAcc@5 100.000 (99.246)\tMem 336MB\n",
      "\u001b[32m[2022-12-06 01:30:51 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [600/788]\tTime 0.046 (0.045)\tLoss 0.5843 (0.4236)\tAcc@1 75.000 (89.954)\tAcc@5 100.000 (99.168)\tMem 336MB\n",
      "\u001b[32m[2022-12-06 01:30:56 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [720/788]\tTime 0.046 (0.045)\tLoss 0.0228 (0.3896)\tAcc@1 100.000 (90.863)\tAcc@5 100.000 (99.255)\tMem 336MB\n",
      "\u001b[32m[2022-12-06 01:30:59 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 90)\u001b[0m: INFO  * Acc@1 91.190 Acc@5 99.286\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Start teacher-student inference\")\n",
    "start_time = time.time()\n",
    "acc1, acc5, loss = teacher_validate(config, data_loader_val, super_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low rank: 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-06 01:28:35 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-12-74e31e303f0c> 1)\u001b[0m: INFO Start teacher-student inference\n",
      "\u001b[32m[2022-12-06 01:28:35 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [0/788]\tTime 0.257 (0.257)\tLoss 0.0000 (0.0000)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\tMem 294MB\n",
      "\u001b[32m[2022-12-06 01:28:41 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [120/788]\tTime 0.043 (0.046)\tLoss 0.0000 (0.2422)\tAcc@1 100.000 (93.492)\tAcc@5 100.000 (99.793)\tMem 346MB\n",
      "\u001b[32m[2022-12-06 01:28:46 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [240/788]\tTime 0.045 (0.045)\tLoss 0.3946 (0.3181)\tAcc@1 87.500 (92.116)\tAcc@5 100.000 (99.689)\tMem 346MB\n",
      "\u001b[32m[2022-12-06 01:28:51 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [360/788]\tTime 0.046 (0.045)\tLoss 0.0060 (0.3519)\tAcc@1 100.000 (91.724)\tAcc@5 100.000 (99.515)\tMem 347MB\n",
      "\u001b[32m[2022-12-06 01:28:57 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [480/788]\tTime 0.046 (0.045)\tLoss 0.8836 (0.3940)\tAcc@1 87.500 (90.826)\tAcc@5 100.000 (99.272)\tMem 347MB\n",
      "\u001b[32m[2022-12-06 01:29:02 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [600/788]\tTime 0.045 (0.045)\tLoss 0.5140 (0.4284)\tAcc@1 75.000 (89.954)\tAcc@5 100.000 (99.126)\tMem 347MB\n",
      "\u001b[32m[2022-12-06 01:29:08 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [720/788]\tTime 0.046 (0.045)\tLoss 0.0113 (0.3934)\tAcc@1 100.000 (90.898)\tAcc@5 100.000 (99.220)\tMem 347MB\n",
      "\u001b[32m[2022-12-06 01:29:11 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 90)\u001b[0m: INFO  * Acc@1 91.175 Acc@5 99.254\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Start teacher-student inference\")\n",
    "start_time = time.time()\n",
    "acc1, acc5, loss = teacher_validate(config, data_loader_val, super_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 175])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_model.state_dict()['layers.' + str(2) + \".blocks.\" + str(0) + \".attn.q_wUSprime\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2 and  3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low rank: 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-06 01:46:25 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-12-74e31e303f0c> 1)\u001b[0m: INFO Start teacher-student inference\n",
      "\u001b[32m[2022-12-06 01:46:25 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [0/788]\tTime 0.263 (0.263)\tLoss 0.0001 (0.0001)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\tMem 291MB\n",
      "\u001b[32m[2022-12-06 01:46:31 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [120/788]\tTime 0.046 (0.048)\tLoss 0.0000 (0.2435)\tAcc@1 100.000 (93.802)\tAcc@5 100.000 (99.690)\tMem 329MB\n",
      "\u001b[32m[2022-12-06 01:46:36 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [240/788]\tTime 0.044 (0.047)\tLoss 0.5867 (0.3031)\tAcc@1 75.000 (91.961)\tAcc@5 100.000 (99.741)\tMem 329MB\n",
      "\u001b[32m[2022-12-06 01:46:42 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [360/788]\tTime 0.047 (0.046)\tLoss 0.0055 (0.3541)\tAcc@1 100.000 (91.136)\tAcc@5 100.000 (99.411)\tMem 329MB\n",
      "\u001b[32m[2022-12-06 01:46:47 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [480/788]\tTime 0.046 (0.046)\tLoss 1.1681 (0.3897)\tAcc@1 87.500 (90.359)\tAcc@5 100.000 (99.194)\tMem 329MB\n",
      "\u001b[32m[2022-12-06 01:46:53 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [600/788]\tTime 0.047 (0.046)\tLoss 0.4617 (0.4216)\tAcc@1 87.500 (89.642)\tAcc@5 100.000 (99.064)\tMem 329MB\n",
      "\u001b[32m[2022-12-06 01:46:59 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 77)\u001b[0m: INFO Test: [720/788]\tTime 0.046 (0.046)\tLoss 0.0286 (0.3834)\tAcc@1 100.000 (90.725)\tAcc@5 100.000 (99.185)\tMem 329MB\n",
      "\u001b[32m[2022-12-06 01:47:02 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-11-d2eb1b709886> 90)\u001b[0m: INFO  * Acc@1 90.968 Acc@5 99.222\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Start teacher-student inference\")\n",
    "start_time = time.time()\n",
    "acc1, acc5, loss = teacher_validate(config, data_loader_val, super_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low Rank 325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-06 01:51:18 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-14-74e31e303f0c> 1)\u001b[0m: INFO Start teacher-student inference\n",
      "\u001b[32m[2022-12-06 01:51:18 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [0/788]\tTime 0.252 (0.252)\tLoss 0.0001 (0.0001)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\tMem 287MB\n",
      "\u001b[32m[2022-12-06 01:51:24 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [120/788]\tTime 0.044 (0.047)\tLoss 0.0000 (0.2544)\tAcc@1 100.000 (93.492)\tAcc@5 100.000 (99.690)\tMem 325MB\n",
      "\u001b[32m[2022-12-06 01:51:29 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [240/788]\tTime 0.044 (0.046)\tLoss 0.5846 (0.3093)\tAcc@1 75.000 (91.649)\tAcc@5 100.000 (99.741)\tMem 325MB\n",
      "\u001b[32m[2022-12-06 01:51:35 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [360/788]\tTime 0.044 (0.046)\tLoss 0.0079 (0.3609)\tAcc@1 100.000 (90.755)\tAcc@5 100.000 (99.411)\tMem 325MB\n",
      "\u001b[32m[2022-12-06 01:51:40 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [480/788]\tTime 0.045 (0.046)\tLoss 1.2177 (0.4001)\tAcc@1 87.500 (89.865)\tAcc@5 100.000 (99.168)\tMem 325MB\n",
      "\u001b[32m[2022-12-06 01:51:46 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [600/788]\tTime 0.045 (0.046)\tLoss 0.6447 (0.4361)\tAcc@1 75.000 (89.185)\tAcc@5 87.500 (99.043)\tMem 326MB\n",
      "\u001b[32m[2022-12-06 01:51:51 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [720/788]\tTime 0.047 (0.046)\tLoss 0.0215 (0.3954)\tAcc@1 100.000 (90.309)\tAcc@5 100.000 (99.150)\tMem 326MB\n",
      "\u001b[32m[2022-12-06 01:51:54 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 90)\u001b[0m: INFO  * Acc@1 90.619 Acc@5 99.190\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Start teacher-student inference\")\n",
    "start_time = time.time()\n",
    "acc1, acc5, loss = teacher_validate(config, data_loader_val, super_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low rank 325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-06 01:54:49 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-14-74e31e303f0c> 1)\u001b[0m: INFO Start teacher-student inference\n",
      "\u001b[32m[2022-12-06 01:54:49 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [0/788]\tTime 0.259 (0.259)\tLoss 0.0002 (0.0002)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\tMem 279MB\n",
      "\u001b[32m[2022-12-06 01:54:55 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [120/788]\tTime 0.048 (0.049)\tLoss 0.0000 (0.2913)\tAcc@1 100.000 (92.665)\tAcc@5 100.000 (99.587)\tMem 308MB\n",
      "\u001b[32m[2022-12-06 01:55:01 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [240/788]\tTime 0.047 (0.048)\tLoss 0.5048 (0.3275)\tAcc@1 75.000 (91.649)\tAcc@5 100.000 (99.689)\tMem 308MB\n",
      "\u001b[32m[2022-12-06 01:55:06 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [360/788]\tTime 0.047 (0.047)\tLoss 0.0049 (0.3830)\tAcc@1 100.000 (90.512)\tAcc@5 100.000 (99.342)\tMem 308MB\n",
      "\u001b[32m[2022-12-06 01:55:12 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [480/788]\tTime 0.048 (0.047)\tLoss 1.3023 (0.4198)\tAcc@1 75.000 (89.579)\tAcc@5 100.000 (99.168)\tMem 308MB\n",
      "\u001b[32m[2022-12-06 01:55:17 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [600/788]\tTime 0.047 (0.047)\tLoss 0.7094 (0.4592)\tAcc@1 87.500 (88.810)\tAcc@5 87.500 (98.918)\tMem 308MB\n",
      "\u001b[32m[2022-12-06 01:55:23 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [720/788]\tTime 0.047 (0.047)\tLoss 0.0363 (0.4170)\tAcc@1 100.000 (89.893)\tAcc@5 100.000 (99.046)\tMem 308MB\n",
      "\u001b[32m[2022-12-06 01:55:26 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 90)\u001b[0m: INFO  * Acc@1 90.175 Acc@5 99.111\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Start teacher-student inference\")\n",
    "start_time = time.time()\n",
    "acc1, acc5, loss = teacher_validate(config, data_loader_val, super_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low rank 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-06 01:57:57 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-14-74e31e303f0c> 1)\u001b[0m: INFO Start teacher-student inference\n",
      "\u001b[32m[2022-12-06 01:57:58 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [0/788]\tTime 0.278 (0.278)\tLoss 0.0022 (0.0022)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\tMem 277MB\n",
      "\u001b[32m[2022-12-06 01:58:03 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [120/788]\tTime 0.045 (0.048)\tLoss 0.0000 (0.3138)\tAcc@1 100.000 (92.149)\tAcc@5 100.000 (99.483)\tMem 306MB\n",
      "\u001b[32m[2022-12-06 01:58:09 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [240/788]\tTime 0.047 (0.047)\tLoss 0.6146 (0.3472)\tAcc@1 75.000 (91.183)\tAcc@5 100.000 (99.689)\tMem 306MB\n",
      "\u001b[32m[2022-12-06 01:58:14 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [360/788]\tTime 0.045 (0.047)\tLoss 0.0043 (0.3985)\tAcc@1 100.000 (90.339)\tAcc@5 100.000 (99.342)\tMem 307MB\n",
      "\u001b[32m[2022-12-06 01:58:20 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [480/788]\tTime 0.048 (0.047)\tLoss 1.5891 (0.4357)\tAcc@1 75.000 (89.423)\tAcc@5 87.500 (99.090)\tMem 307MB\n",
      "\u001b[32m[2022-12-06 01:58:26 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [600/788]\tTime 0.048 (0.047)\tLoss 0.8034 (0.4762)\tAcc@1 75.000 (88.623)\tAcc@5 87.500 (98.814)\tMem 307MB\n",
      "\u001b[32m[2022-12-06 01:58:31 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [720/788]\tTime 0.048 (0.047)\tLoss 0.0429 (0.4318)\tAcc@1 100.000 (89.736)\tAcc@5 100.000 (98.977)\tMem 307MB\n",
      "\u001b[32m[2022-12-06 01:58:35 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 90)\u001b[0m: INFO  * Acc@1 89.968 Acc@5 99.048\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Start teacher-student inference\")\n",
    "start_time = time.time()\n",
    "acc1, acc5, loss = teacher_validate(config, data_loader_val, super_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low rank 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-06 02:02:43 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-14-74e31e303f0c> 1)\u001b[0m: INFO Start teacher-student inference\n",
      "\u001b[32m[2022-12-06 02:02:44 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [0/788]\tTime 0.271 (0.271)\tLoss 0.4580 (0.4580)\tAcc@1 87.500 (87.500)\tAcc@5 100.000 (100.000)\tMem 268MB\n",
      "\u001b[32m[2022-12-06 02:02:49 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [120/788]\tTime 0.043 (0.046)\tLoss 0.0016 (0.5120)\tAcc@1 100.000 (87.190)\tAcc@5 100.000 (98.140)\tMem 297MB\n",
      "\u001b[32m[2022-12-06 02:02:54 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [240/788]\tTime 0.045 (0.045)\tLoss 2.1114 (0.5598)\tAcc@1 62.500 (85.996)\tAcc@5 100.000 (98.651)\tMem 297MB\n",
      "\u001b[32m[2022-12-06 02:03:00 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [360/788]\tTime 0.046 (0.045)\tLoss 0.4972 (0.6211)\tAcc@1 87.500 (85.007)\tAcc@5 100.000 (98.269)\tMem 297MB\n",
      "\u001b[32m[2022-12-06 02:03:05 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [480/788]\tTime 0.044 (0.045)\tLoss 2.9960 (0.6689)\tAcc@1 37.500 (83.758)\tAcc@5 87.500 (98.077)\tMem 297MB\n",
      "\u001b[32m[2022-12-06 02:03:10 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [600/788]\tTime 0.044 (0.045)\tLoss 1.6380 (0.7440)\tAcc@1 75.000 (82.612)\tAcc@5 75.000 (97.525)\tMem 297MB\n",
      "\u001b[32m[2022-12-06 02:03:16 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 77)\u001b[0m: INFO Test: [720/788]\tTime 0.046 (0.045)\tLoss 0.0273 (0.6995)\tAcc@1 100.000 (83.651)\tAcc@5 100.000 (97.746)\tMem 297MB\n",
      "\u001b[32m[2022-12-06 02:03:19 swin_tiny_patch4_window7_224_resisc45]\u001b[0m\u001b[33m(<ipython-input-13-d2eb1b709886> 90)\u001b[0m: INFO  * Acc@1 83.921 Acc@5 97.873\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Start teacher-student inference\")\n",
    "start_time = time.time()\n",
    "acc1, acc5, loss = teacher_validate(config, data_loader_val, super_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
